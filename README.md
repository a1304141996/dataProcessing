# dataProcessing

# 项目说明文档

## 项目概述

本项目是一个基于对话数据的语言风格匹配（LSM）分析与模型微调系统。项目通过分析咨询师与咨询者之间的对话，提取功能词百分比、LSM值和相关语言特征，并利用这些特征训练模型来预测用户是否愿意付费。

## 项目结构 
```
项目根目录/
├── pretreatment/         # 数据预处理模块
│   ├── function_word.py  # 功能词典处理
│   ├── merge_dialogue.py # 对话合并处理
│   ├── split_dialogue.py # 对话分割处理
│   └── dataSet.py        # 数据集生成
├── dataProcessing/           # 数据处理模块
│   ├── Calculate_FW.py       # 功能词百分比计算
│   ├── Calculate_LSM.py      # LSM值计算
│   ├── Calculate_rLSM.py     # 相对LSM值计算
│   ├── config.py             # 配置文件
│   ├── main.py               # 主程序
│   └── text_processing_utils.py # 文本处理工具
└── fineTurning.py            # 模型微调程序
```
## 数据处理流程

### 1. 数据预处理 (pretreatment)

数据预处理阶段主要处理原始对话数据，为后续特征提取做准备。

#### 1.1 功能词典处理 (function_word.py)

- **功能**：处理原始功能词典，去除词性标识，只保留功能词部分
- **输入**：原始功能词典文件（包含词性标识）
- **输出**：纯功能词词典文件

#### 1.2 对话合并处理 (merge_dialogue.py)

- **功能**：将分散的对话合并为一人一句的形式
- **输入**：原始对话文本文件
- **输出**：合并后的对话文本文件，每个发言者的连续发言被合并为一条

#### 1.3 对话分割处理 (split_dialogue.py)

- **功能**：将对话按咨询师和咨询者分开，便于计算LSM值
- **输入**：合并后的对话文本文件
- **输出**：分别包含咨询师和咨询者对话的文本文件

### 2. 数据处理 (dataProcessing)

数据处理阶段主要提取对话中的语言特征，计算功能词百分比、LSM值和相对LSM值。

#### 2.1 配置文件 (config.py)

- **功能**：存储各种文件路径和配置参数
- **内容**：功能词典路径、输入输出目录等

#### 2.2 文本处理工具 (text_processing_utils.py)

- **功能**：提供通用的文本处理函数
- **主要功能**：加载功能词、分段处理、清理文本、计算功能词百分比等

#### 2.3 功能词百分比计算 (Calculate_FW.py)

- **功能**：计算每条对话中功能词的百分比
- **输入**：合并后的对话文本文件
- **输出**：包含对话内容和功能词百分比的Excel文件

#### 2.4 LSM值计算 (Calculate_LSM.py)

- **功能**：计算咨询师和咨询者之间的语言风格匹配度
- **输入**：分割后的咨询师和咨询者对话文件
- **输出**：LSM值列表

#### 2.5 相对LSM值计算 (Calculate_rLSM.py)

- **功能**：计算相邻对话之间的相对语言风格匹配度
- **输入**：功能词百分比Excel文件和LSM值
- **输出**：更新后的Excel文件，包含rLSM和M_rLSM值

#### 2.6 主程序 (main.py)

- **功能**：协调整个数据处理流程
- **流程**：加载功能词 → 计算功能词百分比 → 计算LSM和rLSM值

### 3. 数据集生成 (dataSet.py)

- **功能**：将处理后的Excel数据转换为JSON格式，便于模型训练
- **输入**：包含对话内容、功能词百分比、LSM和rLSM值的Excel文件
- **输出**：结构化的JSON文件，包含全局指标和对话数据

### 4. 模型微调 (fineTurning.py)

- **功能**：基于处理后的数据微调预训练语言模型
- **模型**：使用Qwen2-1.5B模型
- **特征**：利用对话内容、功能词百分比、LSM和rLSM值作为输入特征
- **目标**：预测用户是否愿意付费（二分类任务）
- **评估**：使用分类报告评估模型性能

## 使用流程

1. **准备功能词典**：运行`function_word.py`处理原始功能词典
2. **预处理对话数据**：
   - 运行`merge_dialogue.py`合并对话
   - 运行`split_dialogue.py`分割对话
3. **提取语言特征**：
   - 运行`main.py`计算功能词百分比、LSM和rLSM值
4. **生成训练数据**：
   - 运行`dataSet.py`生成JSON格式的训练数据
5. **模型微调**：
   - 运行`fineTurning.py`微调预训练模型

## 数据流向
原始对话数据 → 合并对话 → 分割对话 → 计算功能词百分比 → 计算LSM和rLSM值 → 生成JSON数据 → 模型微调

## 模型架构

模型采用了基于Qwen2-1.5B的自定义架构，主要特点包括：

1. **输入特征**：
   - 对话文本内容（通过预训练模型编码）
   - 功能词百分比（每句话中功能词的比例）
   - 相对LSM值（相邻对话之间的语言风格匹配度）
   - 全局LSM值（整个对话的语言风格匹配度）
   - M_rLSM值（平均相对LSM值）

2. **模型结构**：
   - 使用预训练的Qwen2-1.5B模型提取文本特征
   - 将文本特征与功能词百分比和rLSM值拼接
   - 使用TransformerEncoder层聚合句子级特征
   - 将聚合特征与全局LSM和M_rLSM值拼接
   - 通过全连接层进行最终分类

3. **训练策略**：
   - 使用交叉熵损失函数
   - Adam优化器
   - 学习率为1e-4
   - 训练5个epoch
   - 使用Wandb进行实验跟踪

## 注意事项

1. 请确保在运行前正确配置`config.py`中的路径
2. 数据处理过程需要按顺序执行，确保每一步的输出正确生成
3. 模型微调需要足够的GPU内存，建议使用支持CUDA的环境

## 依赖库

- pandas
- numpy
- jieba
- openpyxl
- torch
- transformers
- scikit-learn
- tqdm
- wandb

## 未来改进方向

1. 优化模型结构，探索不同的特征融合方式
2. 增加更多语言特征，如情感分析、话题一致性等
3. 尝试不同的预训练模型，如BERT、GPT等
4. 实现更细粒度的预测，如预测用户付费意愿的程度
5. 开发可视化工具，直观展示LSM分析结果
